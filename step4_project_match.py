import json
import os
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer, models  # <--- æ³¨æ„è¿™é‡Œå¼•å…¥äº† models
import time

# ================= é…ç½®è·¯å¾„ =================

# 1. è¾“å…¥ï¼šä½ çš„ JSON æŠ€æœ¯æ ‘æ–‡ä»¶
JSON_FILE_PATH = r"D:\predict\0.1\data\2024_tree.json"

# 2. è¾“å…¥ï¼šç¬¬2æ­¥ç”Ÿæˆçš„å¤–éƒ¨æ ‡ç­¾æ•°æ®
EMBEDDING_DIR = r"D:\predict\0.1\embeddings_output"

# 3. æ¨¡å‹è·¯å¾„
LOCAL_MODEL_PATH = r"D:\predict\models\bge-large-zh-v1.5"

# 4. è¾“å‡ºï¼šæœ€ç»ˆç»“æœ Excel
OUTPUT_EXCEL = r"D:\predict\0.1\2024_Project_Final_Labels.xlsx"

# 5. å‚æ•°
TOP_K = 3  # æ¯ä¸ªé¡¹ç›®åŒ¹é…å‰3ä¸ªå¤–éƒ¨æ ‡ç­¾

# ================= æ ¸å¿ƒä»£ç  =================

def load_external_data():
    """åŠ è½½ç¬¬2æ­¥ç”Ÿæˆçš„å¤–éƒ¨å‘é‡åº“"""
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½å¤–éƒ¨æ ‡ç­¾åº“: {EMBEDDING_DIR}")
    try:
        ext_emb = np.load(os.path.join(EMBEDDING_DIR, "external_embeddings.npy"))
        with open(os.path.join(EMBEDDING_DIR, "external_labels_clean.txt"), 'r', encoding='utf-8') as f:
            ext_labels = [line.strip() for line in f]
        return ext_emb, ext_labels
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¬¬2æ­¥æ˜¯å¦æˆåŠŸè¿è¡Œã€‚é”™è¯¯: {e}")
        exit()

def extract_projects_from_json(file_path):
    """é€’å½’è§£æJSONæ ‘ï¼Œæå–æ‰€æœ‰é¡¹ç›®åŠå…¶è·¯å¾„"""
    print(f"ğŸ“‚ æ­£åœ¨è¯»å– JSON: {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    project_list = [] 

    def recurse(node, path_str):
        current_name = node.get("name", "Root")
        new_path = f"{path_str} > {current_name}" if path_str else current_name
        
        if "projects" in node and isinstance(node["projects"], list):
            for proj in node["projects"]:
                if proj and isinstance(proj, str):
                    project_list.append({
                        "é¡¹ç›®åç§°": proj,
                        "åŸå†…éƒ¨è·¯å¾„": new_path
                    })
        
        if "children" in node and isinstance(node["children"], list):
            for child in node["children"]:
                recurse(child, new_path)

    if isinstance(data, dict):
        recurse(data, "")
    elif isinstance(data, list):
        for item in data:
            recurse(item, "")
            
    print(f"âœ… JSON è§£æå®Œæˆï¼Œå…±æå–åˆ° {len(project_list)} ä¸ªé¡¹ç›®")
    return project_list

def load_model_manually(model_path):
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘æ‰‹åŠ¨ç»„è£…æ¨¡å‹ï¼Œè§£å†³ç¼ºå¤± modules.json å¯¼è‡´çš„ Pooling é”™è¯¯
    """
    print(f"\nâ¬‡ï¸  æ­£åœ¨æ‰‹åŠ¨ç»„è£… BGE æ¨¡å‹: {model_path}")
    try:
        # 1. åŠ è½½åŸºç¡€ Transformer æ¨¡å‹ (åªè¯»å– config.json å’Œ pytorch_model.bin)
        word_embedding_model = models.Transformer(model_path, max_seq_length=512)
        
        # 2. å®šä¹‰ Pooling å±‚
        # BGE æ¨¡å‹é€šå¸¸ä½¿ç”¨ CLS æ ‡è®°ä½œä¸ºå¥å‘é‡ (pooling_mode_cls_token=True)
        pooling_model = models.Pooling(
            word_embedding_model.get_word_embedding_dimension(),
            pooling_mode_cls_token=True,  # BGE æ¨èä½¿ç”¨ CLS
            pooling_mode_mean_tokens=False,
            pooling_mode_max_tokens=False
        )
        
        # 3. ç»„åˆæˆ SentenceTransformer
        model = SentenceTransformer(modules=[word_embedding_model, pooling_model])
        print("âœ… æ¨¡å‹ç»„è£…åŠ è½½æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½ä¾ç„¶å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿æ–‡ä»¶å¤¹é‡Œè‡³å°‘æœ‰ config.json å’Œ pytorch_model.bin (æˆ– model.safetensors)")
        exit()

def main():
    print("="*50)
    print("ğŸš€ å¼€å§‹ç¬¬ 4 æ­¥ï¼šé¡¹ç›®çº§ç²¾å‡†æ˜ å°„ (ä¿®å¤ç‰ˆ)")
    print("="*50)

    # 1. åŠ è½½å¤–éƒ¨åº“
    ext_emb, ext_labels = load_external_data()

    # 2. æå–é¡¹ç›®
    all_projects = extract_projects_from_json(JSON_FILE_PATH)
    if not all_projects:
        print("âŒ JSONä¸­æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
        return
    
    df_projects = pd.DataFrame(all_projects)
    project_names = df_projects["é¡¹ç›®åç§°"].tolist()

    # 3. ã€ä¿®æ”¹ã€‘è°ƒç”¨æ‰‹åŠ¨åŠ è½½å‡½æ•°
    model = load_model_manually(LOCAL_MODEL_PATH)
    
    print(f"âš¡ æ­£åœ¨è®¡ç®— {len(project_names)} ä¸ªé¡¹ç›®çš„å‘é‡...")
    start_time = time.time()
    project_embeddings = model.encode(project_names, normalize_embeddings=True, show_progress_bar=True)
    print(f"âœ… è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f} ç§’")

    # 4. æ ¸å¿ƒåŒ¹é…
    print("\nğŸ” æ­£åœ¨è¿›è¡Œè¯­ä¹‰åŒ¹é…...")
    similarity_matrix = np.dot(project_embeddings, ext_emb.T)

    # 5. æ•´ç†ç»“æœ
    final_results = []
    
    for i, row in df_projects.iterrows():
        proj_name = row["é¡¹ç›®åç§°"]
        path_info = row["åŸå†…éƒ¨è·¯å¾„"]
        
        scores = similarity_matrix[i]
        top_indices = scores.argsort()[-TOP_K:][::-1]
        
        res_item = {
            "é¡¹ç›®åç§°": proj_name,
            "åŸå†…éƒ¨è·¯å¾„": path_info
        }
        
        for rank, idx in enumerate(top_indices):
            res_item[f"å¤–éƒ¨æ ‡ç­¾_{rank+1}"] = ext_labels[idx]
            res_item[f"ç›¸ä¼¼åº¦_{rank+1}"] = round(float(scores[idx]), 4)
            
        final_results.append(res_item)

    # 6. ä¿å­˜ Excel
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æœ€ç»ˆç»“æœåˆ°: {OUTPUT_EXCEL}")
    df_final = pd.DataFrame(final_results)
    df_final.to_excel(OUTPUT_EXCEL, index=False)
    
    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼è¯·æŸ¥çœ‹ç»“æœæ–‡ä»¶ï¼š{OUTPUT_EXCEL}")

if __name__ == "__main__":
    main()