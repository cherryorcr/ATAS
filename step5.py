import json
import os
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer, models
import time
import torch
import re

# ================= âš™ï¸ é…ç½®è·¯å¾„ =================

JSON_FILE_PATH = r"D:\predict\0.1\data\2021_tree.json"
EXTERNAL_TXT_PATH = r"D:\predict\0.1\lables"  # ä»£ç ä¼šè‡ªåŠ¨å¤„ç†åç¼€é—®é¢˜
LOCAL_MODEL_PATH = r"D:\predict\models\bge-large-zh-v1.5"

# ç¼“å­˜çš„å‘é‡æ–‡ä»¶ (å¿…é¡»å­˜åœ¨)
CACHE_EMB_PATH = r"D:\predict\0.1\2021project_embeddings_cache.npy"

# æœ€ç»ˆä¿®å¤ç»“æœ
OUTPUT_CSV_FIXED = r"D:\predict\data\åˆåŒä¿¡æ¯\2021_Project_Final_Fixed.csv"


# ================= ä»£ç  =================

def load_model_for_external(model_path):
    """åªç”¨æ¥ç®—å¤–éƒ¨æ ‡ç­¾ï¼Œå¾ˆå¿«"""
    print(f"â¬‡ï¸  åŠ è½½æ¨¡å‹(ä»…è®¡ç®—å¤–éƒ¨æ ‡ç­¾): {model_path}")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    word_embedding_model = models.Transformer(model_path, max_seq_length=512)
    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode_cls_token=True)
    return SentenceTransformer(modules=[word_embedding_model, pooling_model], device=device)


def extract_projects(file_path):
    print(f"ğŸ“‚ å†æ¬¡è¯»å– JSON (ç¡®ä¿é¡ºåºä¸€è‡´): {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    projects = []

    def recurse(node, path):
        name = node.get("name", "Root")
        curr_path = f"{path} > {name}" if path else name
        if "projects" in node:
            for p in node["projects"]:
                if p: projects.append({"é¡¹ç›®åç§°": p, "åŸå†…éƒ¨è·¯å¾„": curr_path})
        if "children" in node:
            for c in node["children"]:
                recurse(c, curr_path)

    if isinstance(data, dict):
        recurse(data, "")
    elif isinstance(data, list):
        for item in data: recurse(item, "")
    return pd.DataFrame(projects)


def clean_text(text):
    """æ¸…æ´—æ‰å¯èƒ½å¯¼è‡´ CSV/Excel é”™ä¹±çš„å­—ç¬¦"""
    if not isinstance(text, str): return text
    # å»é™¤æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦
    text = text.replace('\n', ' ').replace('\r', '').replace('\t', ' ')
    # å»é™¤ Excel éæ³•æ§åˆ¶å­—ç¬¦
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', text)
    return text.strip()


def get_real_file_path(base_path):
    """ã€ä¿®å¤ã€‘æ™ºèƒ½æŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸ç®¡æ˜¯ lables è¿˜æ˜¯ lables.txt"""
    if os.path.exists(base_path):
        return base_path
    elif os.path.exists(base_path + ".txt"):
        return base_path + ".txt"
    else:
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å¤–éƒ¨æ ‡ç­¾æ–‡ä»¶: {base_path} æˆ– {base_path}.txt")


def main():
    print("=" * 50)
    print("ğŸš€ å¯åŠ¨ä¿®å¤è„šæœ¬ (åˆ©ç”¨ç¼“å­˜ç§’çº§å®Œæˆ)")
    print("=" * 50)

    # 1. è¯»å–é¡¹ç›®åˆ—è¡¨
    df_projects = extract_projects(JSON_FILE_PATH)
    print(f"ğŸ“Š é¡¹ç›®æ•°é‡: {len(df_projects)}")

    # 2. è¯»å–ç¼“å­˜å‘é‡
    if not os.path.exists(CACHE_EMB_PATH):
        print(f"âŒ ä¸¥é‡é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¼“å­˜æ–‡ä»¶ {CACHE_EMB_PATH}")
        print("   è¯·ç¡®è®¤ä¸Šä¸€æ­¥æ˜¯å¦ç”Ÿæˆäº† .npy æ–‡ä»¶ã€‚")
        return

    print(f"âš¡ è¯»å–é¡¹ç›®å‘é‡ç¼“å­˜: {CACHE_EMB_PATH}")
    proj_emb = np.load(CACHE_EMB_PATH)

    if len(proj_emb) != len(df_projects):
        print(f"âŒ é”™è¯¯ï¼šé¡¹ç›®æ•°é‡({len(df_projects)}) ä¸ å‘é‡æ•°é‡({len(proj_emb)}) ä¸ä¸€è‡´ï¼")
        print("   è¿™è¯´æ˜ JSON æ–‡ä»¶å¯èƒ½è¢«æ”¹è¿‡ï¼Œæˆ–è€…ç¼“å­˜æ˜¯æ—§çš„ã€‚è¯·é‡æ–°è¿è¡Œå®Œæ•´æµç¨‹ã€‚")
        return

    # 3. è®¡ç®—å¤–éƒ¨æ ‡ç­¾å‘é‡
    real_label_path = get_real_file_path(EXTERNAL_TXT_PATH)
    print(f"ğŸ·ï¸  åŠ è½½å¤–éƒ¨æ ‡ç­¾æ–‡ä»¶: {real_label_path}")

    with open(real_label_path, 'r', encoding='utf-8') as f:
        ext_labels = [line.strip() for line in f if line.strip()]

    # åŠ è½½æ¨¡å‹è®¡ç®—å¤–éƒ¨æ ‡ç­¾
    model = load_model_for_external(LOCAL_MODEL_PATH)
    ext_emb = model.encode(ext_labels, normalize_embeddings=True, show_progress_bar=False)

    # 4. åŒ¹é…
    print("ğŸ” æ­£åœ¨æ‰§è¡ŒåŒ¹é…...")
    sim_matrix = np.dot(proj_emb, ext_emb.T)

    # 5. ç»„è£…ç»“æœ
    print("ğŸ“¦ æ­£åœ¨ç»„è£…æ•°æ®è¡¨...")
    results = []
    top_k = 3

    for i in range(len(df_projects)):
        scores = sim_matrix[i]
        top_idx = scores.argsort()[-top_k:][::-1]

        # è·å–åŸå§‹ä¿¡æ¯
        row_data = df_projects.iloc[i].to_dict()

        # æ¸…æ´—åŸå§‹é¡¹ç›®åå’Œè·¯å¾„ (é˜²æ­¢é‡Œé¢çš„æ¢è¡Œç¬¦ç ´å CSV)
        row_data["é¡¹ç›®åç§°"] = clean_text(row_data["é¡¹ç›®åç§°"])
        row_data["åŸå†…éƒ¨è·¯å¾„"] = clean_text(row_data["åŸå†…éƒ¨è·¯å¾„"])

        # å¡«å…¥åŒ¹é…ç»“æœ
        for rank, idx in enumerate(top_idx):
            row_data[f"å¤–éƒ¨æ ‡ç­¾_{rank + 1}"] = ext_labels[idx]
            row_data[f"ç›¸ä¼¼åº¦_{rank + 1}"] = round(float(scores[idx]), 4)

        results.append(row_data)

    # 6. ä¿å­˜
    df_final = pd.DataFrame(results)

    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ä¿®å¤åçš„ CSV: {OUTPUT_CSV_FIXED}")
    # quoting=1 (QUOTE_ALL) å¼ºåˆ¶åŠ å¼•å·ï¼Œå®Œç¾è§£å†³ CSV é”™è¡Œé—®é¢˜
    df_final.to_csv(OUTPUT_CSV_FIXED, index=False, encoding='utf-8-sig', quoting=1)

    print("âœ… ä¿®å¤å®Œæˆï¼è¯·æŸ¥çœ‹æ–°ç”Ÿæˆçš„ CSV æ–‡ä»¶ã€‚")


if __name__ == "__main__":
    main()